{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Tracktolib","text":"<p>Tracktolib is a Swiss-knife utility library for Python, providing helpers for PostgreSQL, S3, FastAPI, and more.</p> <p> </p>"},{"location":"#installation","title":"Installation","text":"<pre><code>uv add tracktolib\n</code></pre> <p>With specific extras:</p> <pre><code>uv add tracktolib[pg-sync,api]\n</code></pre>"},{"location":"#available-extras","title":"Available Extras","text":"Extra Description <code>pg</code> Async PostgreSQL helpers (asyncpg) <code>pg-sync</code> Sync PostgreSQL helpers (psycopg v3) <code>s3</code> Async S3 helpers (aiobotocore) <code>s3-minio</code> S3 helpers (minio) <code>s3-niquests</code> S3 helpers (niquests + botocore) <code>api</code> FastAPI utilities <code>http</code> HTTP client helpers (httpx) - deprecated <code>logs</code> Logging configuration <code>notion</code> Notion API helpers <code>tests</code> Testing utilities (deepdiff)"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from psycopg import connect\nfrom tracktolib.pg_sync import insert_many, fetch_one, fetch_all\n\nconn = connect('postgresql://user:pass@localhost/db')\n\ndata = [\n    {'foo': 'bar', 'value': 1},\n    {'foo': 'baz', 'value': 2}\n]\ninsert_many(conn, 'public.test', data)\n\nvalue = fetch_one(conn, 'SELECT foo from public.test order by value asc', required=True)\n# {'foo': 'bar'}\n\nassert fetch_all(conn, 'SELECT * from public.test order by value asc') == data\n</code></pre>"},{"location":"modules/","title":"Modules","text":"<p>Tracktolib is organized into modules, each providing utilities for specific use cases. Install only what you need using extras.</p>"},{"location":"modules/#database","title":"Database","text":"Module Extra Description PostgreSQL (Async) <code>pg</code> Async PostgreSQL helpers using asyncpg PostgreSQL (Sync) <code>pg-sync</code> Sync PostgreSQL helpers using psycopg v3"},{"location":"modules/#storage","title":"Storage","text":"Module Extra Description S3 (Async) <code>s3-niquests</code> Async S3 helpers using niquests + botocore S3 (MinIO) <code>s3-minio</code> S3 helpers using MinIO client S3 (aiobotocore) <code>s3</code> Async S3 helpers using aiobotocore (deprecated)"},{"location":"modules/#web","title":"Web","text":"Module Extra Description API (FastAPI) <code>api</code> FastAPI utilities and endpoint builders Cloudflare <code>cf</code> Cloudflare DNS API helpers GitHub <code>gh</code> GitHub API helpers HTTP <code>http</code> HTTP client helpers (deprecated) Notion <code>notion</code> Notion API helpers"},{"location":"modules/#utilities","title":"Utilities","text":"Module Extra Description Logs <code>logs</code> Logging configuration (JSON/console) Tests <code>tests</code> Testing utilities with deepdiff"},{"location":"modules/#installation-examples","title":"Installation Examples","text":"<p>Install a single extra:</p> <pre><code>uv add tracktolib[pg]\n</code></pre> <p>Install multiple extras:</p> <pre><code>uv add tracktolib[pg,api,logs]\n</code></pre> <p>Install all extras:</p> <pre><code>uv add tracktolib[pg,pg-sync,s3,s3-minio,s3-niquests,api,cf,gh,http,logs,tests,notion]\n</code></pre>"},{"location":"modules/api/","title":"API (FastAPI)","text":"<p>FastAPI utilities for building REST APIs with type-safe endpoints.</p>"},{"location":"modules/api/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[api]\n</code></pre>"},{"location":"modules/api/#dependencies","title":"Dependencies","text":"<ul> <li>fastapi</li> <li>pydantic</li> </ul>"},{"location":"modules/api/#quick-start","title":"Quick Start","text":"<pre><code>from fastapi import APIRouter\nfrom pydantic import BaseModel\nfrom tracktolib.api import Endpoint, add_endpoint, Depends\n\nrouter = APIRouter()\n\n\nclass User(BaseModel):\n    id: int\n    name: str\n\n\nusers_endpoint = Endpoint()\n\n\n@users_endpoint.get()\nasync def get_users() -&gt; list[User]:\n    \"\"\"Get all users.\"\"\"\n    return [User(id=1, name='John')]\n\n\n@users_endpoint.post(status_code=201)\nasync def create_user(user: User) -&gt; User:\n    \"\"\"Create a new user.\"\"\"\n    return user\n\n\nadd_endpoint('/users', router, users_endpoint)\n</code></pre>"},{"location":"modules/api/#endpoint-class","title":"Endpoint Class","text":"<p>The <code>Endpoint</code> class provides a clean way to define HTTP methods for a route.</p>"},{"location":"modules/api/#available-methods","title":"Available Methods","text":"<pre><code>from tracktolib.api import Endpoint\n\nendpoint = Endpoint()\n\n\n@endpoint.get()\nasync def get_item() -&gt; Item: ...\n\n\n@endpoint.post(status_code=201)\nasync def create_item(item: Item) -&gt; Item: ...\n\n\n@endpoint.put()\nasync def update_item(id: int, item: Item) -&gt; Item: ...\n\n\n@endpoint.patch()\nasync def partial_update(id: int, data: dict) -&gt; Item: ...\n\n\n@endpoint.delete(status_code=204)\nasync def delete_item(id: int) -&gt; None: ...\n</code></pre>"},{"location":"modules/api/#path-extensions","title":"Path Extensions","text":"<pre><code>endpoint = Endpoint()\n\n\n@endpoint.get()\nasync def list_items() -&gt; list[Item]: ...\n\n\n@endpoint.get(path='{item_id}')\nasync def get_item(item_id: int) -&gt; Item: ...\n\n# Results in:\n# GET /items -&gt; list_items\n# GET /items/{item_id} -&gt; get_item\n</code></pre>"},{"location":"modules/api/#type-safe-dependencies","title":"Type-Safe Dependencies","text":"<p>The <code>Depends</code> function provides type-safe dependency injection.</p> <pre><code>from tracktolib.api import Depends\n\n\nasync def get_db() -&gt; Database:\n    return Database()\n\n\nasync def get_current_user(db: Database = Depends(get_db)) -&gt; User:\n    return User(id=1, name='John')\n\n\n@endpoint.get()\nasync def get_profile(user: User = Depends(get_current_user)) -&gt; User:\n    \"\"\"Get current user profile.\"\"\"\n    return user\n</code></pre>"},{"location":"modules/api/#adding-endpoints-to-router","title":"Adding Endpoints to Router","text":"<pre><code>from fastapi import APIRouter\nfrom tracktolib.api import add_endpoint, Endpoint\n\nrouter = APIRouter()\n\nusers = Endpoint()\n# ... define methods\n\nadd_endpoint(\n    path='/users',\n    router=router,\n    endpoint=users,\n    dependencies=[Depends(verify_token)]  # Applied to all methods\n)\n</code></pre>"},{"location":"modules/api/#response-utilities","title":"Response Utilities","text":""},{"location":"modules/api/#jsonserialresponse","title":"<code>JSONSerialResponse</code>","text":"<p>Custom JSON response with extended serialization support.</p> <pre><code>from fastapi import FastAPI\nfrom tracktolib.api import JSONSerialResponse\nfrom datetime import datetime\nfrom decimal import Decimal\n\napp = FastAPI(\n    title='My API',\n    default_response_class=JSONSerialResponse,\n)\n\n\n# All routes now automatically handle:\n# - datetime objects\n# - Decimal\n# - UUID\n# - Custom objects with __json__ method\n\n@app.get('/data')\nasync def get_data():\n    return {\n        'timestamp': datetime.now(),\n        'amount': Decimal('99.99')\n    }\n</code></pre>"},{"location":"modules/api/#check_status","title":"<code>check_status</code>","text":"<p>Assert response status in tests, otherwise raise AssertionError with the response json content.</p> <pre><code>from tracktolib.api import check_status\n\nresponse = client.get('/users')\ncheck_status(response)  # Asserts 200\n\nresponse = client.post('/users', json={...})\ncheck_status(response, status=201)\n</code></pre>"},{"location":"modules/api/#pydantic-utilities","title":"Pydantic Utilities","text":""},{"location":"modules/api/#camelcasemodel","title":"<code>CamelCaseModel</code>","text":"<p>Base model that converts field names to camelCase in JSON.</p> <pre><code>from tracktolib.api import CamelCaseModel\n\n\nclass UserResponse(CamelCaseModel):\n    user_id: int\n    first_name: str\n    created_at: datetime\n\n# JSON output:\n# {\"userId\": 1, \"firstName\": \"John\", \"createdAt\": \"...\"}\n</code></pre>"},{"location":"modules/api/#openapi-enhancements","title":"OpenAPI Enhancements","text":""},{"location":"modules/api/#list-response-names","title":"List Response Names","text":"<p>Automatically generates proper names for list responses in OpenAPI.</p> <pre><code>@endpoint.get(model=list[User])\nasync def get_users() -&gt; list[User]:\n    \"\"\"Get all users.\"\"\"\n    ...\n\n# OpenAPI schema will show \"Array[User]\" instead of generic \"List\"\n</code></pre>"},{"location":"modules/api/#complete-example","title":"Complete Example","text":"<pre><code>from fastapi import FastAPI, APIRouter\nfrom pydantic import BaseModel\nfrom tracktolib.api import Endpoint, add_endpoint, Depends, CamelCaseModel\n\napp = FastAPI()\nrouter = APIRouter(prefix='/api/v1')\n\n\n# Models\nclass UserCreate(CamelCaseModel):\n    first_name: str\n    email: str\n\n\nclass UserResponse(CamelCaseModel):\n    user_id: int\n    first_name: str\n    email: str\n\n\n# Dependencies\nasync def get_db():\n    yield database\n\n\n# Endpoints\nusers = Endpoint()\n\n\n@users.get()\nasync def list_users(db=Depends(get_db)) -&gt; list[UserResponse]:\n    \"\"\"List all users.\"\"\"\n    return await db.fetch_all_users()\n\n\n@users.get(path='{user_id}')\nasync def get_user(user_id: int, db=Depends(get_db)) -&gt; UserResponse:\n    \"\"\"Get user by ID.\"\"\"\n    return await db.fetch_user(user_id)\n\n\n@users.post(status_code=201)\nasync def create_user(user: UserCreate, db=Depends(get_db)) -&gt; UserResponse:\n    \"\"\"Create a new user.\"\"\"\n    return await db.create_user(user)\n\n\n@users.delete(path='{user_id}', status_code=204)\nasync def delete_user(user_id: int, db=Depends(get_db)) -&gt; None:\n    \"\"\"Delete a user.\"\"\"\n    await db.delete_user(user_id)\n\n\n# Register\nadd_endpoint('/users', router, users)\napp.include_router(router)\n</code></pre>"},{"location":"modules/cf/","title":"Cloudflare","text":"<p>Cloudflare DNS API helpers using niquests.</p>"},{"location":"modules/cf/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[cf]\n</code></pre>"},{"location":"modules/cf/#dependencies","title":"Dependencies","text":"<ul> <li>niquests - Modern HTTP client with HTTP/3 support</li> </ul>"},{"location":"modules/cf/#overview","title":"Overview","text":"<p>This module provides an async client for the Cloudflare DNS API:</p> <ul> <li>DNS record management (get, create, update, delete)</li> <li>Support for any record type (CNAME, A, AAAA, TXT, etc.)</li> <li>Existence checks</li> </ul>"},{"location":"modules/cf/#authentication","title":"Authentication","text":"<p>The client uses environment variables by default:</p> <ul> <li><code>CLOUDFLARE_API_TOKEN</code> - API token with DNS edit permissions</li> <li><code>CLOUDFLARE_ZONE_ID</code> - Zone ID for the domain</li> </ul> <pre><code>from tracktolib.cf import CloudflareDNSClient\n\nasync with CloudflareDNSClient() as cf:\n    # ... use client\n</code></pre> <p>Or pass credentials explicitly:</p> <pre><code>async with CloudflareDNSClient(token=\"xxx\", zone_id=\"yyy\") as cf:\n    # ... use client\n</code></pre>"},{"location":"modules/cf/#dns-records","title":"DNS Records","text":""},{"location":"modules/cf/#get_dns_recordname-record_type-dnsrecord-none","title":"<code>get_dns_record(name, record_type) -&gt; DnsRecord | None</code>","text":"<p>Get a DNS record by name and type. Returns <code>None</code> if not found.</p> <pre><code>record = await cf.get_dns_record(\"app.example.com\", \"CNAME\")\nif record:\n    print(f\"{record['name']} -&gt; {record['content']}\")\n</code></pre>"},{"location":"modules/cf/#create_dns_recordname-content-record_type-ttl-proxied-comment-dnsrecord","title":"<code>create_dns_record(name, content, record_type, *, ttl, proxied, comment) -&gt; DnsRecord</code>","text":"<p>Create a DNS record. The <code>ttl</code> parameter defaults to <code>1</code> (automatic).</p> <pre><code>record = await cf.create_dns_record(\n    \"app.example.com\",\n    \"target.example.com\",\n    record_type=\"CNAME\",\n    ttl=60,\n    proxied=True,\n    comment=\"Created by deployment script\",\n)\nprint(f\"Created record {record['id']}\")\n</code></pre>"},{"location":"modules/cf/#update_dns_recordrecord_id-content-name-record_type-ttl-proxied-comment-dnsrecord","title":"<code>update_dns_record(record_id, *, content, name, record_type, ttl, proxied, comment) -&gt; DnsRecord</code>","text":"<p>Update a DNS record by ID. Only the provided fields will be updated; omitted fields remain unchanged.</p> <pre><code>record = await cf.update_dns_record(\n    \"023e105f4ecef8ad9ca31a8372d0c353\",\n    content=\"new-target.example.com\",\n    proxied=True,\n)\nprint(f\"Updated record {record['name']} -&gt; {record['content']}\")\n</code></pre>"},{"location":"modules/cf/#delete_dns_recordrecord_id-none","title":"<code>delete_dns_record(record_id) -&gt; None</code>","text":"<p>Delete a DNS record by ID.</p> <pre><code>await cf.delete_dns_record(\"023e105f4ecef8ad9ca31a8372d0c353\")\n</code></pre>"},{"location":"modules/cf/#delete_dns_record_by_namename-record_type-bool","title":"<code>delete_dns_record_by_name(name, record_type) -&gt; bool</code>","text":"<p>Delete a DNS record by name and type. Returns <code>True</code> if deleted, <code>False</code> if not found.</p> <pre><code>if await cf.delete_dns_record_by_name(\"app.example.com\", \"CNAME\"):\n    print(\"Record deleted\")\nelse:\n    print(\"Record not found\")\n</code></pre>"},{"location":"modules/cf/#dns_record_existsname-record_type-bool","title":"<code>dns_record_exists(name, record_type) -&gt; bool</code>","text":"<p>Check if a DNS record exists.</p> <pre><code>if await cf.dns_record_exists(\"app.example.com\"):\n    print(\"Record exists\")\n</code></pre>"},{"location":"modules/cf/#configuration","title":"Configuration","text":""},{"location":"modules/cf/#retries","title":"Retries","text":"<p>Configure automatic retries:</p> <pre><code>from urllib3.util.retry import Retry\n\nretry = Retry(total=3, backoff_factor=0.5)\nasync with CloudflareDNSClient(retries=retry) as cf:\n    # ...\n</code></pre>"},{"location":"modules/cf/#request-hooks","title":"Request Hooks","text":"<p>Add custom hooks for logging or metrics:</p> <pre><code>def log_response(response, **kwargs):\n    print(f\"{response.request.method} {response.url} -&gt; {response.status_code}\")\n\nasync with CloudflareDNSClient(hooks={\"response\": [log_response]}) as cf:\n    # ...\n</code></pre>"},{"location":"modules/cf/#error-handling","title":"Error Handling","text":"<p>The client raises <code>CloudflareError</code> on API failures:</p> <pre><code>from tracktolib.cf import CloudflareDNSClient, CloudflareError\n\ntry:\n    await cf.create_dns_record(\"invalid\", \"target.com\")\nexcept CloudflareError as e:\n    print(f\"Cloudflare API error: {e}\")\n    print(f\"Status code: {e.status_code}\")\n    print(f\"Errors: {e.errors}\")\n</code></pre>"},{"location":"modules/cf/#types","title":"Types","text":"<p>The module exports a TypedDict for DNS record responses:</p> <ul> <li><code>DnsRecord</code> - DNS record data (id, name, type, content, ttl, proxied, etc.)</li> </ul> <pre><code>from tracktolib.cf import DnsRecord\n</code></pre>"},{"location":"modules/gh/","title":"GitHub","text":"<p>GitHub API helpers using niquests.</p>"},{"location":"modules/gh/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[gh]\n</code></pre>"},{"location":"modules/gh/#dependencies","title":"Dependencies","text":"<ul> <li>niquests - Modern HTTP client with HTTP/3 support</li> </ul>"},{"location":"modules/gh/#overview","title":"Overview","text":"<p>This module provides an async client for the GitHub REST API:</p> <ul> <li>Issue and PR comment management (create, delete, idempotent operations)</li> <li>Label management (add, remove, list)</li> <li>Deployment status management (list, mark inactive)</li> </ul>"},{"location":"modules/gh/#authentication","title":"Authentication","text":"<p>The client uses the <code>GITHUB_TOKEN</code> environment variable by default:</p> <pre><code>from tracktolib.gh import GitHubClient\n\nasync with GitHubClient() as gh:\n    # ... use client\n</code></pre> <p>Or pass a token explicitly:</p> <pre><code>async with GitHubClient(token=\"ghp_xxx\") as gh:\n    # ... use client\n</code></pre>"},{"location":"modules/gh/#issue-comments","title":"Issue Comments","text":""},{"location":"modules/gh/#get_issue_commentsrepository-issue_number-listissuecomment","title":"<code>get_issue_comments(repository, issue_number) -&gt; list[IssueComment]</code>","text":"<p>Get all comments on an issue or PR.</p> <pre><code>comments = await gh.get_issue_comments(\"owner/repo\", 123)\nfor c in comments:\n    print(f\"{c['user']['login']}: {c['body']}\")\n</code></pre>"},{"location":"modules/gh/#create_issue_commentrepository-issue_number-body-issuecomment","title":"<code>create_issue_comment(repository, issue_number, body) -&gt; IssueComment</code>","text":"<p>Create a comment on an issue or PR.</p> <pre><code>comment = await gh.create_issue_comment(\"owner/repo\", 123, \"Hello from bot!\")\nprint(f\"Created comment {comment['id']}\")\n</code></pre>"},{"location":"modules/gh/#delete_issue_commentrepository-comment_id-none","title":"<code>delete_issue_comment(repository, comment_id) -&gt; None</code>","text":"<p>Delete a comment by ID.</p> <pre><code>await gh.delete_issue_comment(\"owner/repo\", 12345678)\n</code></pre>"},{"location":"modules/gh/#find_comments_with_markerrepository-issue_number-marker-listint","title":"<code>find_comments_with_marker(repository, issue_number, marker) -&gt; list[int]</code>","text":"<p>Find comment IDs containing a specific marker string.</p> <pre><code># Find all bot comments\nids = await gh.find_comments_with_marker(\"owner/repo\", 123, \"&lt;!-- my-bot --&gt;\")\n</code></pre>"},{"location":"modules/gh/#delete_comments_with_markerrepository-issue_number-marker-on_progress-int","title":"<code>delete_comments_with_marker(repository, issue_number, marker, *, on_progress) -&gt; int</code>","text":"<p>Delete all comments containing a specific marker. Returns the count of deleted comments.</p> <pre><code>deleted = await gh.delete_comments_with_marker(\n    \"owner/repo\", 123, \"&lt;!-- preview-bot --&gt;\",\n    on_progress=lambda i, total: print(f\"Deleted {i}/{total}\")\n)\nprint(f\"Removed {deleted} old bot comments\")\n</code></pre>"},{"location":"modules/gh/#create_idempotent_commentrepository-issue_number-body-marker-issuecomment-none","title":"<code>create_idempotent_comment(repository, issue_number, body, marker) -&gt; IssueComment | None</code>","text":"<p>Create a comment only if one with the marker doesn't already exist. Returns the created comment, or <code>None</code> if skipped.</p> <pre><code># Only post once per PR\nbody = \"&lt;!-- ci-status --&gt;\\n## Build Status\\n...\"\ncomment = await gh.create_idempotent_comment(\"owner/repo\", 123, body, \"&lt;!-- ci-status --&gt;\")\nif comment:\n    print(\"Posted new status comment\")\nelse:\n    print(\"Status comment already exists\")\n</code></pre>"},{"location":"modules/gh/#labels","title":"Labels","text":""},{"location":"modules/gh/#get_issue_labelsrepository-issue_number-listlabel","title":"<code>get_issue_labels(repository, issue_number) -&gt; list[Label]</code>","text":"<p>Get all labels on an issue or PR.</p> <pre><code>labels = await gh.get_issue_labels(\"owner/repo\", 123)\nprint([l[\"name\"] for l in labels])\n</code></pre>"},{"location":"modules/gh/#add_labelsrepository-issue_number-labels-listlabel","title":"<code>add_labels(repository, issue_number, labels) -&gt; list[Label]</code>","text":"<p>Add labels to an issue or PR.</p> <pre><code>await gh.add_labels(\"owner/repo\", 123, [\"bug\", \"priority:high\"])\n</code></pre>"},{"location":"modules/gh/#remove_labelrepository-issue_number-label-bool","title":"<code>remove_label(repository, issue_number, label) -&gt; bool</code>","text":"<p>Remove a label from an issue or PR. Returns <code>True</code> if removed, <code>False</code> if not found.</p> <pre><code>if await gh.remove_label(\"owner/repo\", 123, \"needs-review\"):\n    print(\"Label removed\")\n</code></pre>"},{"location":"modules/gh/#deployments","title":"Deployments","text":""},{"location":"modules/gh/#get_deploymentsrepository-environment-listdeployment","title":"<code>get_deployments(repository, *, environment) -&gt; list[Deployment]</code>","text":"<p>Get deployments, optionally filtered by environment.</p> <pre><code># All deployments\ndeploys = await gh.get_deployments(\"owner/repo\")\n\n# Filter by environment\npreview_deploys = await gh.get_deployments(\"owner/repo\", environment=\"preview-123\")\n</code></pre>"},{"location":"modules/gh/#get_deployment_statusesrepository-deployment_id-listdeploymentstatus","title":"<code>get_deployment_statuses(repository, deployment_id) -&gt; list[DeploymentStatus]</code>","text":"<p>Get all statuses for a deployment, most recent first.</p> <pre><code>statuses = await gh.get_deployment_statuses(\"owner/repo\", 123456)\nfor status in statuses:\n    print(f\"{status['state']} at {status['created_at']}\")\n</code></pre>"},{"location":"modules/gh/#get_latest_deployment_statusrepository-environment-deploymentstatus-none","title":"<code>get_latest_deployment_status(repository, environment) -&gt; DeploymentStatus | None</code>","text":"<p>Get the latest deployment status for an environment. Returns <code>None</code> if no deployments exist.</p> <pre><code>status = await gh.get_latest_deployment_status(\"owner/repo\", \"production\")\nif status:\n    print(f\"Production is {status['state']}\")\n</code></pre>"},{"location":"modules/gh/#create_deployment_statusrepository-deployment_id-state-description-environment_url-deploymentstatus","title":"<code>create_deployment_status(repository, deployment_id, state, *, description, environment_url) -&gt; DeploymentStatus</code>","text":"<p>Create a deployment status. State can be: <code>error</code>, <code>failure</code>, <code>inactive</code>, <code>in_progress</code>, <code>queued</code>, <code>pending</code>, <code>success</code>.</p> <pre><code>status = await gh.create_deployment_status(\n    \"owner/repo\",\n    deployment_id=123456,\n    state=\"success\",\n    description=\"Deployed successfully\",\n    environment_url=\"https://preview-123.example.com\",\n)\n</code></pre>"},{"location":"modules/gh/#mark_deployment_inactiverepository-environment-description-on_progress-int","title":"<code>mark_deployment_inactive(repository, environment, *, description, on_progress) -&gt; int</code>","text":"<p>Mark all deployments for an environment as inactive. Returns the count of updated deployments.</p> <pre><code># Clean up preview environment when PR is closed\ncount = await gh.mark_deployment_inactive(\n    \"owner/repo\",\n    \"preview-pr-42\",\n    description=\"PR closed\",\n    on_progress=lambda i, total: print(f\"Deactivated {i}/{total}\"),\n)\nprint(f\"Marked {count} deployments as inactive\")\n</code></pre>"},{"location":"modules/gh/#configuration","title":"Configuration","text":""},{"location":"modules/gh/#custom-base-url","title":"Custom Base URL","text":"<p>For GitHub Enterprise:</p> <pre><code>async with GitHubClient(base_url=\"https://github.mycompany.com/api/v3\") as gh:\n    # ...\n</code></pre>"},{"location":"modules/gh/#retries","title":"Retries","text":"<p>Configure automatic retries:</p> <pre><code>from urllib3.util.retry import Retry\n\nretry = Retry(total=3, backoff_factor=0.5)\nasync with GitHubClient(retries=retry) as gh:\n    # ...\n</code></pre>"},{"location":"modules/gh/#request-hooks","title":"Request Hooks","text":"<p>Add custom hooks for logging or metrics:</p> <pre><code>def log_response(response, **kwargs):\n    print(f\"{response.request.method} {response.url} -&gt; {response.status_code}\")\n\nasync with GitHubClient(hooks={\"response\": [log_response]}) as gh:\n    # ...\n</code></pre>"},{"location":"modules/gh/#error-handling","title":"Error Handling","text":"<p>The client uses <code>raise_for_status()</code> on all API responses, raising <code>niquests.HTTPError</code> on failures:</p> <pre><code>from niquests import HTTPError\n\ntry:\n    await gh.create_issue_comment(\"owner/repo\", 999999, \"test\")\nexcept HTTPError as e:\n    print(f\"GitHub API error: {e.response.status_code} - {e.response.text}\")\n</code></pre>"},{"location":"modules/gh/#types","title":"Types","text":"<p>The module exports TypedDict types generated from GitHub's OpenAPI spec:</p> <ul> <li><code>IssueComment</code> - Issue/PR comment data</li> <li><code>Label</code> - Label data</li> <li><code>Deployment</code> - Deployment data</li> <li><code>DeploymentStatus</code> - Deployment status data</li> <li><code>ProgressCallback</code> - Type alias for progress callbacks <code>Callable[[int, int], None]</code></li> </ul> <pre><code>from tracktolib.gh import IssueComment, Label, Deployment, DeploymentStatus, ProgressCallback\n</code></pre>"},{"location":"modules/http/","title":"HTTP (Deprecated)","text":"<p>Deprecation Notice</p> <p>This module is deprecated and will be removed in a future version. Consider using httpx directly or other HTTP clients.</p> <p>HTTP client helpers using httpx.</p>"},{"location":"modules/http/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[http]\n</code></pre>"},{"location":"modules/http/#dependencies","title":"Dependencies","text":"<ul> <li>httpx</li> </ul>"},{"location":"modules/http/#functions","title":"Functions","text":""},{"location":"modules/http/#download_file","title":"<code>download_file</code>","text":"<p>Download a file with streaming and progress callbacks.</p> <pre><code>import httpx\nfrom pathlib import Path\nfrom tracktolib.http_utils import download_file\n\nasync with httpx.AsyncClient() as client:\n    with open('output.bin', 'wb') as f:\n        await download_file(\n            url='https://example.com/large-file.zip',\n            client=client,\n            output_file=f,\n            chunk_size=10 * 1024 * 1024  # 10MB chunks\n        )\n</code></pre>"},{"location":"modules/http/#complete-example","title":"Complete Example","text":"<pre><code>import httpx\nfrom pathlib import Path\nfrom tracktolib.http_utils import download_file, get_progress\n\n\nasync def download_with_progress(url: str, output_path: Path):\n    total_downloaded = 0\n\n    def on_progress(total_size: int, chunk_size: int):\n        nonlocal total_downloaded\n        total_downloaded += chunk_size\n        percent = (total_downloaded / total_size) * 100\n        print(f\"\\rDownloading: {percent:.1f}% ({total_downloaded}/{total_size})\", end='')\n\n    on_response, on_chunk = get_progress(on_progress)\n\n    async with httpx.AsyncClient() as client:\n        with output_path.open('wb') as f:\n            await download_file(\n                url=url,\n                client=client,\n                output_file=f,\n                on_response=on_response,\n                on_chunk_received=on_chunk\n            )\n\n    print(\"\\nDownload complete!\")\n\n\n# Usage\nimport asyncio\n\nasyncio.run(download_with_progress(\n    'https://example.com/large-file.zip',\n    Path('downloaded.zip')\n))\n</code></pre>"},{"location":"modules/logs/","title":"Logs","text":"<p>Utility functions to initialize logging formatting and streams.</p>"},{"location":"modules/logs/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[logs]\n</code></pre>"},{"location":"modules/logs/#dependencies","title":"Dependencies","text":"<ul> <li>python-json-logger</li> </ul>"},{"location":"modules/logs/#functions","title":"Functions","text":""},{"location":"modules/logs/#init_logging","title":"<code>init_logging</code>","text":"<p>Initialize logging with either JSON or console format.</p> <pre><code>import logging\nfrom tracktolib.logs import init_logging\n\nlogger = logging.getLogger()\n\n# JSON format (for production/structured logging)\nformatter, stream_handler = init_logging(logger, 'json', version='0.0.1')\n\n# Console format (for development)\nformatter, stream_handler = init_logging(logger, 'console', version='0.0.1')\n</code></pre>"},{"location":"modules/logs/#is_valid_log_format","title":"<code>is_valid_log_format</code>","text":"<p>Type guard to validate log format strings.</p> <pre><code>from tracktolib.logs import is_valid_log_format\n\nuser_input = \"json\"\nif is_valid_log_format(user_input):\n    # user_input is now typed as LogFormat\n    formatter, handler = init_logging(logger, user_input, version='1.0.0')\n</code></pre>"},{"location":"modules/logs/#custom-json-formatter","title":"Custom JSON Formatter","text":"<p>The <code>CustomJsonFormatter</code> class extends <code>JsonFormatter</code> to automatically include the application version in every log entry.</p>"},{"location":"modules/logs/#extending-the-formatter","title":"Extending the Formatter","text":"<p>You can extend <code>CustomJsonFormatter</code> to automatically inject the version from your app config:</p> <pre><code>from tracktolib.logs import CustomJsonFormatter\n\n\nclass AppJsonFormatter(CustomJsonFormatter):\n    def __init__(self, *args, **kwargs):\n        from myapp.config import VERSION\n        super().__init__(version=VERSION, *args, **kwargs)\n</code></pre>"},{"location":"modules/logs/#integration-with-uvicornfastapi","title":"Integration with Uvicorn/FastAPI","text":"<p>Example of integrating with uvicorn's logging configuration:</p> <pre><code>import logging\nfrom uvicorn.config import LOGGING_CONFIG\nfrom tracktolib.logs import init_logging as _init_logging, is_valid_log_format\n\n\ndef init_logging(\n        logger: logging.Logger,\n        logs_format: str,\n        logger_name: str,\n        version: str,\n        log_level: int = logging.INFO,\n):\n    if not is_valid_log_format(logs_format):\n        raise ValueError(f\"Got invalid log format: {logs_format!r}\")\n\n    log_config = {**LOGGING_CONFIG}\n    log_config['loggers'][logger_name] = {'handlers': ['default'], 'level': log_level}\n\n    use_colors = True\n    formatter, stream_handler = _init_logging(logger=logger, log_format=logs_format, version=version)\n\n    if logs_format == 'json':\n        log_config['formatters']['json'] = {\n            '()': 'myapp.logs.AppJsonFormatter',\n            'fmt': '%(asctime)s [%(levelname)s] %(message)s',\n        }\n        log_config['handlers']['default']['formatter'] = 'json'\n        log_config['handlers']['access']['formatter'] = 'json'\n        use_colors = False\n\n    stream_handler.setFormatter(formatter)\n    logger.addHandler(stream_handler)\n\n    return log_config, use_colors\n</code></pre>"},{"location":"modules/logs/#output-examples","title":"Output Examples","text":""},{"location":"modules/logs/#json-format","title":"JSON Format","text":"<pre><code>{\n  \"asctime\": \"2024-01-15 10:30:45\",\n  \"levelname\": \"INFO\",\n  \"message\": \"Application started\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>"},{"location":"modules/logs/#console-format","title":"Console Format","text":"<pre><code>2024-01-15 10:30:45 [INFO] Application started\n</code></pre>"},{"location":"modules/notion/","title":"Notion","text":"<p>Notion API helpers using niquests.</p>"},{"location":"modules/notion/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[notion]\n</code></pre>"},{"location":"modules/notion/#dependencies","title":"Dependencies","text":"<ul> <li>niquests - Modern HTTP client with HTTP/3 support</li> </ul>"},{"location":"modules/notion/#overview","title":"Overview","text":"<p>This module provides utilities for interacting with the Notion API:</p> <ul> <li>Block creation helpers for building Notion content programmatically</li> <li>High-level utilities for exporting/importing pages as markdown</li> <li>Persistent caching for databases and page content</li> </ul>"},{"location":"modules/notion/#authentication","title":"Authentication","text":"<p>Set up a session with Notion headers:</p> <pre><code>import niquests\nfrom tracktolib.notion.fetch import get_notion_headers\n\n# Using environment variable (NOTION_TOKEN)\nheaders = get_notion_headers()\n\n# Or with explicit token\nheaders = get_notion_headers(token=\"secret_xxx\")\n\nasync with niquests.AsyncSession() as session:\n    session.headers.update(headers)\n    # ... use session for API calls\n</code></pre>"},{"location":"modules/notion/#high-level-utilities","title":"High-Level Utilities","text":""},{"location":"modules/notion/#export_markdown_to_page-exportresult","title":"<code>export_markdown_to_page(...) -&gt; ExportResult</code>","text":"<p>Export markdown content to a Notion database as a new page.</p> <pre><code>result = await export_markdown_to_page(\n    session,\n    database_id=\"your-database-id\",\n    content=\"# My Document\\n\\nContent here...\",\n    title=\"Document Title\",\n    properties={\"Tags\": {\"multi_select\": [{\"name\": \"docs\"}]}},\n    comments=[\"Initial review comment\", \"Another comment\"],\n)\nprint(f\"Created {result['count']} blocks at {result['url']}\")\n</code></pre> <p>Comments handling: The optional <code>comments</code> parameter accepts a list of strings. Each string is added as a page-level comment (not attached to any specific block) after the page is created.</p>"},{"location":"modules/notion/#download_page_to_markdown-int","title":"<code>download_page_to_markdown(...) -&gt; int</code>","text":"<p>Download a Notion page to a local markdown file.</p> <pre><code>block_count = await download_page_to_markdown(\n    session,\n    page_id=\"your-page-id\",\n    output_path=\"./output.md\",\n    include_comments=True,\n    on_progress=lambda current, total: print(f\"Fetched: {current}\"),\n)\n</code></pre> <p>Comments handling: When <code>include_comments=True</code>, the function fetches both:</p> <ul> <li>Inline block comments: Rendered as blockquotes immediately after their associated block</li> <li>Page-level comments: Appended at the end under a <code>## Comments</code> heading</li> </ul> <p>Comments are formatted as:</p> <pre><code>&gt; \ud83d\udcac **Author Name** - 2024-01-15 10:30: Comment text here\n</code></pre> <p>When re-uploading downloaded markdown with <code>update_page_content</code>, comment blockquotes (lines starting with <code>&gt; \ud83d\udcac</code>) are automatically stripped to avoid converting them into regular quote blocks.</p>"},{"location":"modules/notion/#update_page_content-updateresult","title":"<code>update_page_content(...) -&gt; UpdateResult</code>","text":"<p>Update a page using smart prefix-preserving diff. Only deletes and recreates blocks that changed, preserving block IDs and inline comments on unchanged content.</p> <pre><code>result = await update_page_content(\n    session,\n    page_id=\"your-page-id\",\n    content=\"# Updated Content\\n\\nNew text here...\",\n)\nprint(f\"Preserved: {result['preserved']}, Deleted: {result['deleted']}, Created: {result['created']}\")\n</code></pre>"},{"location":"modules/notion/#clear_page_blocks-clearresult","title":"<code>clear_page_blocks(...) -&gt; ClearResult</code>","text":"<p>Delete all blocks from a Notion page.</p> <pre><code>result = await clear_page_blocks(session, page_id=\"your-page-id\")\nprint(f\"Deleted {result['deleted']} blocks\")\n</code></pre>"},{"location":"modules/notion/#fetch_all_page_comments-listpagecomment","title":"<code>fetch_all_page_comments(...) -&gt; list[PageComment]</code>","text":"<p>Fetch all comments from a page and its blocks.</p> <pre><code>comments = await fetch_all_page_comments(\n    session,\n    page_id=\"your-page-id\",\n    concurrency=50,\n)\nfor c in comments:\n    print(f\"{c['author_name']}: {c['text']}\")\n</code></pre>"},{"location":"modules/notion/#caching","title":"Caching","text":""},{"location":"modules/notion/#notioncache","title":"<code>NotionCache</code>","text":"<p>Persistent cache for Notion data. Use as a context manager to auto-load on entry and save on exit:</p> <pre><code>from tracktolib.notion import NotionCache\n\nwith NotionCache() as cache:\n    # Databases\n    db = cache.get_database(\"db-id\")  # Returns CachedDatabase | None\n    cache.set_database(database_response)\n    cache.delete_database(\"db-id\")\n\n    # Page blocks\n    blocks = cache.get_page_blocks(\"page-id\")\n    cache.set_page_blocks(\"page-id\", blocks)\n    cache.delete_page_blocks(\"page-id\")\n\n    # Page comments\n    comments = cache.get_page_comments(\"page-id\")\n    cache.set_page_comments(\"page-id\", comments)\n    cache.delete_page_comments(\"page-id\")\n\n    # Clear all\n    cache.clear()\n# Automatically saved on exit\n</code></pre> <p>Default cache location: <code>~/.cache/tracktolib/notion/cache.json</code></p> <p>Custom location:</p> <pre><code>from pathlib import Path\n\ncache = NotionCache(cache_dir=Path(\"/custom/cache/dir\"))\n</code></pre>"},{"location":"modules/notion/#cacheddatabase","title":"<code>CachedDatabase</code>","text":"<p>TypedDict with cached database info: <code>id</code>, <code>title</code>, <code>properties</code>, <code>cached_at</code>.</p>"},{"location":"modules/notion/#concurrency","title":"Concurrency","text":"<p>High-level functions accept an optional <code>semaphore</code> parameter for rate limiting (default: 50 concurrent requests):</p> <pre><code>import asyncio\n\nsemaphore = asyncio.Semaphore(10)\nawait clear_page_blocks(session, page_id, semaphore=semaphore)\n</code></pre>"},{"location":"modules/pg-sync/","title":"PostgreSQL (Sync)","text":"<p>Sync PostgreSQL helpers using psycopg (v3).</p>"},{"location":"modules/pg-sync/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[pg-sync]\n</code></pre>"},{"location":"modules/pg-sync/#dependencies","title":"Dependencies","text":"<ul> <li>psycopg (v3)</li> </ul>"},{"location":"modules/pg-sync/#quick-start","title":"Quick Start","text":"<pre><code>from psycopg import connect\nfrom tracktolib.pg_sync import insert_many, fetch_one, fetch_all, fetch_count\n\nconn = connect('postgresql://user:pass@localhost/db')\n\n# Insert data\ndata = [\n    {'name': 'Alice', 'value': 1},\n    {'name': 'Bob', 'value': 2}\n]\ninsert_many(conn, 'public.users', data)\n\n# Fetch single row\nuser = fetch_one(conn, 'SELECT * FROM users WHERE id = %s', 1, required=True)\n\n# Fetch all rows\nusers = fetch_all(conn, 'SELECT * FROM users ORDER BY id')\n\n# Count rows\ncount = fetch_count(conn, 'public.users')\n</code></pre>"},{"location":"modules/pg-sync/#fetch-functions","title":"Fetch Functions","text":""},{"location":"modules/pg-sync/#fetch_all","title":"<code>fetch_all</code>","text":"<p>Fetch all rows from a query as a list of dictionaries.</p> <pre><code>from tracktolib.pg_sync import fetch_all\n\n# Simple query\nusers = fetch_all(conn, 'SELECT * FROM users')\n\n# With parameters\nactive_users = fetch_all(\n    conn,\n    'SELECT * FROM users WHERE status = %s ORDER BY name',\n    'active'\n)\n</code></pre>"},{"location":"modules/pg-sync/#fetch_one","title":"<code>fetch_one</code>","text":"<p>Fetch a single row from a query.</p> <pre><code>from tracktolib.pg_sync import fetch_one\n\n# Optional result (returns None if not found)\nuser = fetch_one(conn, 'SELECT * FROM users WHERE id = %s', 42)\n\n# Required result (raises ValueError if not found)\nuser = fetch_one(conn, 'SELECT * FROM users WHERE id = %s', 42, required=True)\n</code></pre>"},{"location":"modules/pg-sync/#fetch_count","title":"<code>fetch_count</code>","text":"<p>Count rows in a table with optional WHERE clause.</p> <pre><code>from tracktolib.pg_sync import fetch_count\n\n# Count all rows\ntotal = fetch_count(conn, 'public.users')\n\n# Count with condition\nactive_count = fetch_count(conn, 'public.users', 'active', where='status = %s')\n</code></pre>"},{"location":"modules/pg-sync/#insert-functions","title":"Insert Functions","text":""},{"location":"modules/pg-sync/#insert_many","title":"<code>insert_many</code>","text":"<p>Insert multiple rows into a table.</p> <pre><code>from tracktolib.pg_sync import insert_many\n\ndata = [\n    {'name': 'Alice', 'email': 'alice@example.com'},\n    {'name': 'Bob', 'email': 'bob@example.com'},\n]\ninsert_many(conn, 'public.users', data)\n</code></pre> <p>The function automatically:</p> <ul> <li>Extracts column names from the first dictionary</li> <li>Converts dict values to JSON when needed</li> <li>Uses <code>executemany</code> for efficient batch inserts</li> </ul>"},{"location":"modules/pg-sync/#insert_one","title":"<code>insert_one</code>","text":"<p>Insert a single row with optional RETURNING clause.</p> <pre><code>from tracktolib.pg_sync import insert_one\n\n# Simple insert\ninsert_one(conn, 'public.users', {'name': 'Charlie', 'email': 'charlie@example.com'})\n\n# Insert with returning\nresult = insert_one(\n    conn,\n    'public.users',\n    {'name': 'Charlie'},\n    returning=['id', 'created_at']\n)\nprint(result['id'])\n</code></pre>"},{"location":"modules/pg-sync/#insert_csv","title":"<code>insert_csv</code>","text":"<p>Bulk insert from a CSV file using PostgreSQL's COPY command.</p> <pre><code>from pathlib import Path\nfrom tracktolib.pg_sync import insert_csv\n\nwith conn.cursor() as cur:\n    insert_csv(\n        cur,\n        schema='public',\n        table='users',\n        csv_path=Path('users.csv'),\n        exclude_columns=['internal_id'],  # Columns to skip\n        delimiter=',',\n        on_conflict='ON CONFLICT DO NOTHING'\n    )\nconn.commit()\n</code></pre>"},{"location":"modules/pg-sync/#table-management","title":"Table Management","text":""},{"location":"modules/pg-sync/#clean_tables","title":"<code>clean_tables</code>","text":"<p>Truncate multiple tables with options for identity reset and cascading.</p> <pre><code>from tracktolib.pg_sync import clean_tables\n\n# Truncate tables and reset sequences\nclean_tables(conn, ['public.orders', 'public.order_items'])\n\n# Without resetting sequences\nclean_tables(conn, ['public.logs'], reset_seq=False)\n\n# Without cascading\nclean_tables(conn, ['public.users'], cascade=False)\n</code></pre>"},{"location":"modules/pg-sync/#get_tables","title":"<code>get_tables</code>","text":"<p>Get all table names in specified schemas.</p> <pre><code>from tracktolib.pg_sync import get_tables\n\n# Get all tables in public schema\ntables = get_tables(conn, ['public'])\n\n# Exclude certain tables\ntables = get_tables(\n    conn,\n    ['public', 'app'],\n    ignored_tables=['public.migrations', 'public.schema_version']\n)\n</code></pre>"},{"location":"modules/pg-sync/#drop_db","title":"<code>drop_db</code>","text":"<p>Drop a database (ignores error if database doesn't exist).</p> <pre><code>from tracktolib.pg_sync import drop_db\n\ndrop_db(conn, 'test_database')\n</code></pre>"},{"location":"modules/pg-sync/#sequence-management","title":"Sequence Management","text":""},{"location":"modules/pg-sync/#set_seq_max","title":"<code>set_seq_max</code>","text":"<p>Set a sequence to the maximum value in a table (useful after bulk inserts).</p> <pre><code>from tracktolib.pg_sync import set_seq_max\n\n# After inserting data with explicit IDs\nset_seq_max(conn, 'users_id_seq', 'public.users')\n</code></pre>"},{"location":"modules/pg-sync/#helper-functions","title":"Helper Functions","text":""},{"location":"modules/pg-sync/#get_insert_data","title":"<code>get_insert_data</code>","text":"<p>Generate INSERT query and values from data.</p> <pre><code>from tracktolib.pg_sync import get_insert_data\n\ndata = [{'name': 'Alice', 'value': 1}]\nquery, values = get_insert_data('public.users', data)\n# query: \"INSERT INTO public.users as t (name,value) VALUES (%s,%s)\"\n# values: [('Alice', 1)]\n</code></pre>"},{"location":"modules/pg-sync/#type-handling","title":"Type Handling","text":"<p>The module automatically handles:</p> <ul> <li>Dictionaries: Converted to <code>Json</code> type for JSONB columns</li> <li>None values: Passed through as NULL</li> <li>All other types: Passed through unchanged</li> </ul>"},{"location":"modules/pg/","title":"PostgreSQL (Async)","text":"<p>Async PostgreSQL helpers using asyncpg.</p>"},{"location":"modules/pg/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[pg]\n</code></pre>"},{"location":"modules/pg/#dependencies","title":"Dependencies","text":"<ul> <li>asyncpg</li> <li>rich (for formatting)</li> </ul>"},{"location":"modules/pg/#quick-start","title":"Quick Start","text":"<pre><code>import asyncpg\nfrom tracktolib.pg import insert_many, insert_one, insert_returning\n\nasync def main():\n    conn = await asyncpg.connect('postgresql://user:pass@localhost/db')\n\n    # Insert single row\n    await insert_one(conn, 'users', {'name': 'John', 'email': 'john@example.com'})\n\n    # Insert multiple rows\n    users = [\n        {'name': 'Alice', 'email': 'alice@example.com'},\n        {'name': 'Bob', 'email': 'bob@example.com'},\n    ]\n    await insert_many(conn, 'users', users)\n\n    # Insert and return the inserted ID\n    user_id = await insert_returning(conn, 'users', {'name': 'Charlie'}, 'id')\n</code></pre>"},{"location":"modules/pg/#insert-functions","title":"Insert Functions","text":""},{"location":"modules/pg/#insert_one","title":"<code>insert_one</code>","text":"<p>Insert a single row into a table.</p> <pre><code>await insert_one(\n    conn,\n    'users',\n    {'name': 'John', 'email': 'john@example.com'},\n    on_conflict='ON CONFLICT DO NOTHING'\n)\n</code></pre>"},{"location":"modules/pg/#insert_many","title":"<code>insert_many</code>","text":"<p>Insert multiple rows into a table.</p> <pre><code>users = [\n    {'name': 'Alice', 'email': 'alice@example.com'},\n    {'name': 'Bob', 'email': 'bob@example.com'},\n]\nawait insert_many(conn, 'users', users)\n\n# With returning\nrecords = await insert_many(conn, 'users', users, returning='id')\n</code></pre>"},{"location":"modules/pg/#insert_returning","title":"<code>insert_returning</code>","text":"<p>Insert and return values from the inserted row.</p> <pre><code># Return single value\nuser_id = await insert_returning(conn, 'users', {'name': 'John'}, 'id')\n\n# Return multiple values\nrecord = await insert_returning(conn, 'users', {'name': 'John'}, ['id', 'created_at'])\n</code></pre>"},{"location":"modules/pg/#update-functions","title":"Update Functions","text":""},{"location":"modules/pg/#update_one","title":"<code>update_one</code>","text":"<p>Update a single row.</p> <pre><code>await update_one(\n    conn,\n    'users',\n    {'id': 1, 'name': 'John Updated'},\n    keys=['id']  # WHERE clause keys\n)\n</code></pre>"},{"location":"modules/pg/#update_many","title":"<code>update_many</code>","text":"<p>Update multiple rows.</p> <pre><code>updates = [\n    {'id': 1, 'status': 'active'},\n    {'id': 2, 'status': 'inactive'},\n]\nawait update_many(conn, 'users', updates, keys=['id'])\n</code></pre>"},{"location":"modules/pg/#update_returning","title":"<code>update_returning</code>","text":"<p>Update and return values.</p> <pre><code>record = await update_returning(\n    conn,\n    'users',\n    {'id': 1, 'name': 'Updated'},\n    keys=['id'],\n    returning=['name', 'updated_at']\n)\n</code></pre>"},{"location":"modules/pg/#query-builders","title":"Query Builders","text":""},{"location":"modules/pg/#pginsertquery","title":"<code>PGInsertQuery</code>","text":"<p>Build complex INSERT queries with conflict handling and returning clauses.</p> <pre><code>from tracktolib.pg import PGInsertQuery, PGConflictQuery, PGReturningQuery\n\nquery = PGInsertQuery(\n    table='users',\n    items=[{'name': 'John', 'email': 'john@example.com'}],\n    on_conflict=PGConflictQuery(keys=['email']),\n    returning=PGReturningQuery.load(keys=['id'])\n)\n\n# Execute\nawait query.run(conn)\n\n# Or fetch results\nresult = await query.fetchrow(conn)\n</code></pre>"},{"location":"modules/pg/#pgupdatequery","title":"<code>PGUpdateQuery</code>","text":"<p>Build complex UPDATE queries.</p> <pre><code>from tracktolib.pg import PGUpdateQuery\n\nquery = PGUpdateQuery(\n    table='users',\n    items=[{'id': 1, 'name': 'Updated', 'status': 'active'}],\n    where_keys=['id'],\n    returning=['name', 'updated_at']\n)\n\nresult = await conn.fetchrow(query.query, *query.values)\n</code></pre>"},{"location":"modules/pg/#conflict-handling","title":"Conflict Handling","text":""},{"location":"modules/pg/#using-conflict-helper","title":"Using <code>Conflict</code> helper","text":"<pre><code>from tracktolib.pg import insert_many, Conflict\n\nawait insert_many(\n    conn,\n    'users',\n    users,\n    on_conflict=Conflict(keys=['email'], ignore_keys=['created_at'])\n)\n</code></pre>"},{"location":"modules/pg/#using-pgconflictquery","title":"Using <code>PGConflictQuery</code>","text":"<pre><code>from tracktolib.pg import PGConflictQuery\n\nconflict = PGConflictQuery(\n    keys=['email'],           # Conflict detection keys\n    ignore_keys=['id'],       # Keys to ignore in update\n    where='t.status != $1',   # Additional WHERE clause\n    merge_keys=['metadata']   # JSONB merge (a || b)\n)\n</code></pre>"},{"location":"modules/pg/#utility-functions","title":"Utility Functions","text":""},{"location":"modules/pg/#fetch_count","title":"<code>fetch_count</code>","text":"<p>Count rows from a query.</p> <pre><code>from tracktolib.pg import fetch_count\n\ncount = await fetch_count(conn, 'SELECT * FROM users WHERE status = $1', 'active')\n</code></pre>"},{"location":"modules/pg/#insert_pg","title":"<code>insert_pg</code>","text":"<p>Factory function to create <code>PGInsertQuery</code> instances.</p> <pre><code>from tracktolib.pg import insert_pg\n\nquery = insert_pg(\n    'users',\n    [{'name': 'John'}],\n    on_conflict='ON CONFLICT DO NOTHING',\n    returning=['id'],\n    fill=True  # Fill missing keys with None\n)\n</code></pre>"},{"location":"modules/pg/#utilities-module","title":"Utilities Module","text":"<p>Additional utilities from <code>tracktolib.pg.utils</code>:</p>"},{"location":"modules/pg/#iterate_pg","title":"<code>iterate_pg</code>","text":"<p>Iterate over large result sets efficiently.</p> <pre><code>from tracktolib.pg import iterate_pg\n\nasync for batch in iterate_pg(conn, 'SELECT * FROM large_table', batch_size=1000):\n    for record in batch:\n        process(record)\n</code></pre>"},{"location":"modules/pg/#safe_pg-safe_pg_context","title":"<code>safe_pg</code> / <code>safe_pg_context</code>","text":"<p>Handle PostgreSQL errors gracefully.</p> <pre><code>from tracktolib.pg import safe_pg, PGError\n\n@safe_pg\nasync def get_user(conn, user_id: int):\n    return await conn.fetchrow('SELECT * FROM users WHERE id = $1', user_id)\n\nresult = await get_user(conn, 1)\nif isinstance(result, PGError):\n    print(f\"Error: {result.message}\")\n</code></pre>"},{"location":"modules/s3-minio/","title":"S3 (MinIO)","text":"<p>S3 helpers using the MinIO Python client.</p>"},{"location":"modules/s3-minio/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[s3-minio]\n</code></pre>"},{"location":"modules/s3-minio/#dependencies","title":"Dependencies","text":"<ul> <li>minio</li> <li>pycryptodome</li> </ul>"},{"location":"modules/s3-minio/#quick-start","title":"Quick Start","text":"<pre><code>from minio import Minio\nfrom pathlib import Path\nfrom tracktolib.s3.minio import download_bucket, upload_object, bucket_rm\n\n# Create client\nminio = Minio(\n    'localhost:9000',\n    access_key='foo',\n    secret_key='foobarbaz',\n    secure=False\n)\n\n# Upload a file\nupload_object(minio, 'my-bucket', 'remote/path.txt', Path('local.txt'))\n\n# Download entire bucket\nfiles = download_bucket(minio, 'my-bucket', Path('./downloads'))\n\n# Remove bucket and all contents\nbucket_rm(minio, 'my-bucket')\n</code></pre>"},{"location":"modules/s3-minio/#functions","title":"Functions","text":""},{"location":"modules/s3-minio/#upload_object","title":"<code>upload_object</code>","text":"<p>Upload a file to a MinIO bucket.</p> <pre><code>from pathlib import Path\nfrom tracktolib.s3.minio import upload_object\n\nupload_object(\n    minio,\n    bucket_name='my-bucket',\n    object_name='uploads/document.pdf',\n    path=Path('/local/path/document.pdf')\n)\n</code></pre>"},{"location":"modules/s3-minio/#download_bucket","title":"<code>download_bucket</code>","text":"<p>Download all objects from a bucket to a local directory.</p> <pre><code>from pathlib import Path\nfrom tracktolib.s3.minio import download_bucket\n\noutput_dir = Path('./downloaded')\nfiles = download_bucket(minio, 'my-bucket', output_dir)\n\n# Returns list of downloaded file paths\nfor file_path in files:\n    print(f\"Downloaded: {file_path}\")\n</code></pre> <p>The function:</p> <ul> <li>Recursively lists all objects in the bucket</li> <li>Creates necessary subdirectories</li> <li>Downloads files in 32KB chunks</li> <li>Returns a list of all downloaded <code>Path</code> objects</li> </ul>"},{"location":"modules/s3-minio/#bucket_rm","title":"<code>bucket_rm</code>","text":"<p>Remove a bucket and all its contents.</p> <pre><code>from tracktolib.s3.minio import bucket_rm\n\n# This will:\n# 1. List all objects in the bucket\n# 2. Delete all objects\n# 3. Remove the bucket itself\nbucket_rm(minio, 'my-bucket')\n</code></pre> <p>Warning</p> <p>This operation is destructive and cannot be undone. All objects in the bucket will be permanently deleted.</p>"},{"location":"modules/s3-minio/#example-backup-and-restore","title":"Example: Backup and Restore","text":"<pre><code>from minio import Minio\nfrom pathlib import Path\nfrom tracktolib.s3.minio import download_bucket, upload_object\n\nminio = Minio('localhost:9000', access_key='key', secret_key='secret', secure=False)\n\n# Backup: Download entire bucket\nbackup_dir = Path('./backup')\nfiles = download_bucket(minio, 'production-data', backup_dir)\nprint(f\"Backed up {len(files)} files\")\n\n# Restore: Upload files to new bucket\nminio.make_bucket('restored-data')\nfor local_file in backup_dir.rglob('*'):\n    if local_file.is_file():\n        object_name = str(local_file.relative_to(backup_dir))\n        upload_object(minio, 'restored-data', object_name, local_file)\n</code></pre>"},{"location":"modules/s3-minio/#connection-examples","title":"Connection Examples","text":""},{"location":"modules/s3-minio/#local-minio","title":"Local MinIO","text":"<pre><code>minio = Minio(\n    'localhost:9000',\n    access_key='minioadmin',\n    secret_key='minioadmin',\n    secure=False  # HTTP\n)\n</code></pre>"},{"location":"modules/s3-minio/#aws-s3","title":"AWS S3","text":"<pre><code>minio = Minio(\n    's3.amazonaws.com',\n    access_key='AWS_ACCESS_KEY',\n    secret_key='AWS_SECRET_KEY',\n    secure=True  # HTTPS\n)\n</code></pre>"},{"location":"modules/s3-minio/#with-region","title":"With Region","text":"<pre><code>minio = Minio(\n    's3.eu-west-1.amazonaws.com',\n    access_key='AWS_ACCESS_KEY',\n    secret_key='AWS_SECRET_KEY',\n    region='eu-west-1'\n)\n</code></pre>"},{"location":"modules/s3-niquests/","title":"S3 (Async)","text":"<p>Async S3 helpers using niquests and botocore.</p>"},{"location":"modules/s3-niquests/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[s3-niquests]\n</code></pre>"},{"location":"modules/s3-niquests/#dependencies","title":"Dependencies","text":"<ul> <li>niquests - HTTP/3 capable requests replacement</li> <li>botocore - AWS SDK core (for presigned URLs generation)</li> </ul>"},{"location":"modules/s3-niquests/#overview","title":"Overview","text":"<p>This module provides async S3 functionality using <code>niquests</code> as the HTTP backend. All S3 operations use presigned URLs, making it compatible with any S3-compatible storage (AWS S3, MinIO, etc.).</p> <p>Key features:</p> <ul> <li>Async context manager for session management</li> <li>Presigned URL-based operations</li> <li>Multipart upload support for large files</li> <li>Streaming upload from async iterators</li> </ul>"},{"location":"modules/s3-niquests/#s3session","title":"S3Session","text":"<p>The recommended way to interact with S3 is through the <code>S3Session</code> class, which manages both the botocore client and niquests async session.</p> <pre><code>from tracktolib.s3.niquests import S3Session\n\nasync with S3Session(\n    endpoint_url='http://localhost:9000',\n    access_key='minioadmin',\n    secret_key='minioadmin',\n    region='us-east-1',\n) as s3:\n    # Upload an object\n    await s3.put_object('my-bucket', 'path/to/file.txt', b'Hello, World!')\n\n    # Download an object\n    content = await s3.get_object('my-bucket', 'path/to/file.txt')\n\n    # Delete an object\n    await s3.delete_object('my-bucket', 'path/to/file.txt')\n</code></pre>"},{"location":"modules/s3-niquests/#methods","title":"Methods","text":"<p>All upload methods accept <code>S3ObjectParams</code> as keyword arguments. See S3 Object Parameters for the full list.</p>"},{"location":"modules/s3-niquests/#put_object","title":"<code>put_object</code>","text":"<p>Upload bytes to S3.</p> <pre><code># Basic upload\nawait s3.put_object('my-bucket', 'file.txt', b'content')\n\n# With parameters\nawait s3.put_object(\n    'my-bucket', 'data.json', b'{\"key\": \"value\"}',\n    acl='private',\n    content_type='application/json',\n    cache_control='max-age=3600',\n    metadata={'author': 'me', 'version': '1.0'},\n)\n</code></pre>"},{"location":"modules/s3-niquests/#get_object","title":"<code>get_object</code>","text":"<p>Download an object. Returns <code>None</code> if not found.</p> <pre><code>content = await s3.get_object('my-bucket', 'file.txt')\nif content is None:\n    print('File not found')\n</code></pre>"},{"location":"modules/s3-niquests/#upload_file","title":"<code>upload_file</code>","text":"<p>Upload a file from disk.</p> <pre><code>from pathlib import Path\n\nawait s3.upload_file('my-bucket', Path('local.txt'), 'remote/path.txt')\n\n# With content type\nawait s3.upload_file(\n    'my-bucket', Path('image.png'), 'images/photo.png',\n    content_type='image/png',\n    cache_control='max-age=86400',\n)\n</code></pre>"},{"location":"modules/s3-niquests/#download_file","title":"<code>download_file</code>","text":"<p>Download a file with streaming support. Returns an async iterator of chunks.</p> <pre><code>async for chunk in s3.download_file('my-bucket', 'large_file.bin'):\n    process(chunk)\n\n# With callbacks and custom chunk size\nasync for chunk in s3.download_file(\n    'my-bucket', 'large_file.bin',\n    chunk_size=512 * 1024,  # 512KB chunks\n    on_chunk=lambda c: print(f'Got {len(c)} bytes'),\n    on_start=lambda resp: print(f'Content-Length: {resp.headers.get(\"content-length\")}'),\n):\n    process(chunk)\n</code></pre>"},{"location":"modules/s3-niquests/#delete_object","title":"<code>delete_object</code>","text":"<p>Delete a single object.</p> <pre><code>await s3.delete_object('my-bucket', 'file.txt')\n</code></pre>"},{"location":"modules/s3-niquests/#delete_objects","title":"<code>delete_objects</code>","text":"<p>Delete multiple objects.</p> <pre><code>await s3.delete_objects('my-bucket', ['file1.txt', 'file2.txt'])\n</code></pre>"},{"location":"modules/s3-niquests/#list_files","title":"<code>list_files</code>","text":"<p>List files with a given prefix. Returns an async iterator.</p> <pre><code>async for f in s3.list_files('my-bucket', 'uploads/'):\n    print(f['Key'], f['Size'])\n\n# With pagination\nasync for f in s3.list_files('my-bucket', 'uploads/', max_items=100, page_size=50):\n    print(f['Key'])\n\n# With JMESPath filter (files larger than 100 bytes)\nasync for f in s3.list_files('my-bucket', 'uploads/', search_query=\"Contents[?Size &gt; `100`][]\"):\n    print(f['Key'], f['Size'])\n</code></pre>"},{"location":"modules/s3-niquests/#file_upload","title":"<code>file_upload</code>","text":"<p>Stream upload from an async iterator. Automatically uses multipart upload for large files.</p> <pre><code>async def read_chunks():\n    with open('large_file.bin', 'rb') as f:\n        while chunk := f.read(1024 * 1024):\n            yield chunk\n\nawait s3.file_upload('my-bucket', 'large_file.bin', read_chunks())\n\n# With parameters\nawait s3.file_upload(\n    'my-bucket', 'video.mp4', read_chunks(),\n    content_type='video/mp4',\n    storage_class='STANDARD_IA',\n    metadata={'duration': '120'},\n)\n</code></pre>"},{"location":"modules/s3-niquests/#multipart_upload","title":"<code>multipart_upload</code>","text":"<p>Low-level multipart upload context manager.</p> <pre><code>async with s3.multipart_upload('my-bucket', 'large_file.bin', acl='private') as upload:\n    await upload.fetch_create()\n    await upload.upload_part(chunk1)\n    await upload.upload_part(chunk2)\n    # Automatically completes on exit, or aborts on exception\n</code></pre>"},{"location":"modules/s3-niquests/#standalone-functions","title":"Standalone Functions","text":"<p>For more control, you can use the standalone functions directly with your own botocore client and niquests session.</p> <pre><code>import botocore.session\nimport niquests\nfrom tracktolib.s3.niquests import s3_put_object, s3_get_object\n\nsession = botocore.session.Session()\ns3_client = session.create_client(\n    's3',\n    endpoint_url='http://localhost:9000',\n    aws_access_key_id='minioadmin',\n    aws_secret_access_key='minioadmin',\n)\n\nasync with niquests.AsyncSession() as http:\n    await s3_put_object(s3_client, http, 'bucket', 'key', b'data')\n    content = await s3_get_object(s3_client, http, 'bucket', 'key')\n</code></pre>"},{"location":"modules/s3-niquests/#available-functions","title":"Available Functions","text":"Function Description <code>s3_put_object</code> Upload bytes to S3 <code>s3_get_object</code> Download an object (returns <code>None</code> if not found) <code>s3_download_file</code> Download with streaming support (async iterator) <code>s3_upload_file</code> Upload a file from disk <code>s3_delete_object</code> Delete a single object <code>s3_delete_objects</code> Delete multiple objects <code>s3_list_files</code> List files with prefix (async iterator) <code>s3_multipart_upload</code> Multipart upload context manager <code>s3_file_upload</code> Stream upload from async iterator <code>s3_put_bucket_policy</code> Set a bucket policy <code>s3_get_bucket_policy</code> Get a bucket policy <code>s3_delete_bucket_policy</code> Delete a bucket policy <code>s3_put_bucket_website</code> Configure static website hosting <code>s3_delete_bucket_website</code> Remove website configuration <code>s3_empty_bucket</code> Delete all objects from a bucket <code>s3_sync_directory</code> Sync a local directory to S3 <code>build_s3_headers</code> Build HTTP headers from <code>S3ObjectParams</code> <code>build_s3_presigned_params</code> Build presigned URL params from <code>S3ObjectParams</code>"},{"location":"modules/s3-niquests/#types","title":"Types","text":"Type Description <code>S3ObjectParams</code> TypedDict for S3 object parameters <code>S3Object</code> TypedDict for S3 object metadata <code>SyncResult</code> TypedDict for sync operation results <code>UploadPart</code> TypedDict for multipart upload part info <code>OnDownloadStartFn</code> Callback type for download start events"},{"location":"modules/s3-niquests/#s3-object-parameters","title":"S3 Object Parameters","text":"<p>All upload methods (<code>put_object</code>, <code>upload_file</code>, <code>file_upload</code>, <code>multipart_upload</code>) accept the following keyword arguments via <code>S3ObjectParams</code>:</p> Parameter Type Description <code>acl</code> <code>str \\| None</code> Canned ACL (optional, no header if omitted) <code>content_type</code> <code>str \\| None</code> MIME type (e.g., <code>'application/json'</code>) <code>content_disposition</code> <code>str \\| None</code> Content-Disposition header <code>content_encoding</code> <code>str \\| None</code> Content encoding (e.g., <code>'gzip'</code>) <code>content_language</code> <code>str \\| None</code> Content language <code>cache_control</code> <code>str \\| None</code> Cache-Control header (e.g., <code>'max-age=3600'</code>) <code>storage_class</code> <code>str \\| None</code> Storage class (see below) <code>server_side_encryption</code> <code>str \\| None</code> SSE algorithm (<code>'AES256'</code>, <code>'aws:kms'</code>) <code>sse_kms_key_id</code> <code>str \\| None</code> KMS key ID for SSE-KMS <code>tagging</code> <code>str \\| None</code> URL-encoded tags (<code>'key1=value1&amp;key2=value2'</code>) <code>metadata</code> <code>dict[str, str] \\| None</code> User-defined metadata"},{"location":"modules/s3-niquests/#acl-values","title":"ACL Values","text":"<ul> <li><code>'private'</code> (default)</li> <li><code>'public-read'</code></li> <li><code>'public-read-write'</code></li> <li><code>'authenticated-read'</code></li> <li><code>'aws-exec-read'</code></li> <li><code>'bucket-owner-read'</code></li> <li><code>'bucket-owner-full-control'</code></li> </ul> <p>Set <code>acl=None</code> to not include any ACL header.</p>"},{"location":"modules/s3-niquests/#storage-classes","title":"Storage Classes","text":"<ul> <li><code>'STANDARD'</code> (default)</li> <li><code>'STANDARD_IA'</code></li> <li><code>'ONEZONE_IA'</code></li> <li><code>'INTELLIGENT_TIERING'</code></li> <li><code>'GLACIER'</code></li> <li><code>'DEEP_ARCHIVE'</code></li> <li><code>'GLACIER_IR'</code></li> <li><code>'EXPRESS_ONEZONE'</code></li> </ul>"},{"location":"modules/s3-niquests/#example","title":"Example","text":"<pre><code>await s3.put_object(\n    'my-bucket', 'reports/data.json', json_bytes,\n    content_type='application/json',\n    cache_control='max-age=86400',\n    storage_class='STANDARD_IA',\n    metadata={'generated_by': 'report-service', 'version': '2.0'},\n    tagging='env=production&amp;team=analytics',\n)\n</code></pre>"},{"location":"modules/s3-niquests/#multipart-upload","title":"Multipart Upload","text":"<p>For large files, use multipart upload to stream data efficiently.</p>"},{"location":"modules/s3-niquests/#using-file_upload","title":"Using <code>file_upload</code>","text":"<p>The simplest way to upload large files from an async stream:</p> <pre><code>async def stream_from_request(request):\n    async for chunk in request.stream():\n        yield chunk\n\nawait s3.file_upload(\n    'my-bucket',\n    'uploaded_file.bin',\n    stream_from_request(request),\n    min_part_size=5 * 1024 * 1024,  # 5MB minimum for S3\n    on_chunk_received=lambda chunk: print(f'Received {len(chunk)} bytes'),\n    content_length=request.headers.get('content-length'),  # optional hint\n)\n</code></pre>"},{"location":"modules/s3-niquests/#using-multipart_upload-directly","title":"Using <code>multipart_upload</code> directly","text":"<p>For more control over the upload process:</p> <pre><code>async with s3.multipart_upload('my-bucket', 'file.bin', expires_in=3600) as upload:\n    await upload.fetch_create()\n\n    # upload_part returns an UploadPart dict with PartNumber and ETag\n    part1 = await upload.upload_part(chunk1)\n    part2 = await upload.upload_part(chunk2)\n\n    # Generate presigned URL for external upload\n    url = upload.generate_presigned_url('upload_part', PartNumber=3)\n\n    # Abort if needed (otherwise completes automatically)\n    # await upload.fetch_abort()\n</code></pre> <p>The context manager automatically:</p> <ul> <li>Completes the upload on successful exit</li> <li>Aborts the upload on exception</li> </ul>"},{"location":"modules/s3-niquests/#bucket-operations","title":"Bucket Operations","text":""},{"location":"modules/s3-niquests/#bucket-policy","title":"Bucket Policy","text":"<p>Manage bucket policies for access control.</p>"},{"location":"modules/s3-niquests/#put_bucket_policy","title":"<code>put_bucket_policy</code>","text":"<p>Set a bucket policy. Accepts a dict or JSON string.</p> <pre><code>policy = {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n        \"Effect\": \"Allow\",\n        \"Principal\": \"*\",\n        \"Action\": \"s3:GetObject\",\n        \"Resource\": f\"arn:aws:s3:::my-bucket/*\"\n    }]\n}\nawait s3.put_bucket_policy('my-bucket', policy)\n</code></pre>"},{"location":"modules/s3-niquests/#get_bucket_policy","title":"<code>get_bucket_policy</code>","text":"<p>Get a bucket policy. Returns <code>None</code> if no policy exists.</p> <pre><code>policy = await s3.get_bucket_policy('my-bucket')\nif policy:\n    print(policy['Statement'])\n</code></pre>"},{"location":"modules/s3-niquests/#delete_bucket_policy","title":"<code>delete_bucket_policy</code>","text":"<p>Delete a bucket policy.</p> <pre><code>await s3.delete_bucket_policy('my-bucket')\n</code></pre>"},{"location":"modules/s3-niquests/#static-website-hosting","title":"Static Website Hosting","text":"<p>Configure buckets for static website hosting.</p> <p>Note: Website configuration is not supported by MinIO.</p>"},{"location":"modules/s3-niquests/#put_bucket_website","title":"<code>put_bucket_website</code>","text":"<p>Configure a bucket as a static website.</p> <pre><code># Basic configuration\nawait s3.put_bucket_website('my-bucket')\n\n# With custom documents\nawait s3.put_bucket_website(\n    'my-bucket',\n    index_document='index.html',\n    error_document='404.html',\n)\n</code></pre>"},{"location":"modules/s3-niquests/#delete_bucket_website","title":"<code>delete_bucket_website</code>","text":"<p>Remove website configuration from a bucket.</p> <pre><code>await s3.delete_bucket_website('my-bucket')\n</code></pre>"},{"location":"modules/s3-niquests/#bucket-cleanup","title":"Bucket Cleanup","text":""},{"location":"modules/s3-niquests/#empty_bucket","title":"<code>empty_bucket</code>","text":"<p>Delete all objects from a bucket. Returns the count of deleted objects.</p> <pre><code>count = await s3.empty_bucket('my-bucket')\nprint(f'Deleted {count} objects')\n\n# With progress callback\ncount = await s3.empty_bucket(\n    'my-bucket',\n    on_progress=lambda key: print(f'Deleted {key}'),\n)\n</code></pre>"},{"location":"modules/s3-niquests/#directory-sync","title":"Directory Sync","text":""},{"location":"modules/s3-niquests/#sync_directory","title":"<code>sync_directory</code>","text":"<p>Sync a local directory to an S3 bucket prefix, similar to <code>aws s3 sync</code>.</p> <p>Compares files using size and modification time: uploads if size differs OR local file is newer than remote. When <code>delete=True</code>, removes remote files that don't exist locally.</p> <pre><code>from pathlib import Path\n\n# Basic sync\nresult = await s3.sync_directory('my-bucket', Path('./local'), 'remote/prefix')\nprint(f\"Uploaded: {len(result['uploaded'])}\")\nprint(f\"Skipped: {len(result['skipped'])}\")\n\n# With delete (removes remote files not present locally)\nresult = await s3.sync_directory(\n    'my-bucket',\n    Path('./local'),\n    'remote/prefix',\n    delete=True,\n)\n\n# With callbacks\nresult = await s3.sync_directory(\n    'my-bucket',\n    Path('./dist'),\n    'static',\n    delete=True,\n    on_upload=lambda path, key: print(f'Uploaded {path} -&gt; {key}'),\n    on_delete=lambda key: print(f'Deleted {key}'),\n    on_skip=lambda path, key: print(f'Skipped {path}'),\n)\n\n# With S3 object parameters\nresult = await s3.sync_directory(\n    'my-bucket',\n    Path('./assets'),\n    'public/assets',\n    acl='public-read',\n    cache_control='max-age=86400',\n)\n</code></pre> <p>Returns a <code>SyncResult</code> dict:</p> <pre><code>{\n    'uploaded': ['remote/prefix/new_file.txt', ...],\n    'deleted': ['remote/prefix/old_file.txt', ...],\n    'skipped': ['remote/prefix/unchanged.txt', ...],\n}\n</code></pre>"},{"location":"modules/s3/","title":"S3 (aiobotocore)","text":"<p>Async S3 helpers using aiobotocore.</p>"},{"location":"modules/s3/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[s3]\n</code></pre>"},{"location":"modules/s3/#dependencies","title":"Dependencies","text":"<ul> <li>aiobotocore</li> </ul>"},{"location":"modules/s3/#quick-start","title":"Quick Start","text":"<pre><code>from pathlib import Path\n\nfrom aiobotocore.session import get_session\nfrom tracktolib.s3.s3 import upload_file, download_file, list_files\n\n\nasync def main():\n    session = get_session()\n    async with session.create_client(\n            's3',\n            endpoint_url='http://localhost:9000',\n            aws_access_key_id='access_key',\n            aws_secret_access_key='secret_key'\n    ) as client:\n        # Upload a file\n        await upload_file(client, 'my-bucket', Path('local.txt'), 'remote/path.txt')\n\n        # Download a file\n        content = await download_file(client, 'my-bucket', 'remote/path.txt')\n\n        # List files\n        files = await list_files(client, 'my-bucket', 'remote/')\n</code></pre>"},{"location":"modules/s3/#functions","title":"Functions","text":""},{"location":"modules/s3/#upload_file","title":"<code>upload_file</code>","text":"<p>Upload a file to S3.</p> <pre><code>from pathlib import Path\nfrom tracktolib.s3.s3 import upload_file\n\nresponse = await upload_file(\n    client,\n    bucket='my-bucket',\n    file=Path('document.pdf'),\n    path='uploads/document.pdf',\n    acl='private'  # or 'public-read', etc.\n)\n</code></pre>"},{"location":"modules/s3/#download_file","title":"<code>download_file</code>","text":"<p>Download a file from S3 with optional progress callbacks.</p> <pre><code>from tracktolib.s3.s3 import download_file\n\n# Simple download\ncontent = await download_file(client, 'my-bucket', 'path/to/file.txt')\nif content:\n    data = content.read()\n\n\n# Download with progress tracking\ndef on_start(total_size: int):\n    print(f\"Starting download: {total_size} bytes\")\n\n\ndef on_update(chunk_size: int):\n    print(f\"Downloaded {chunk_size} bytes\")\n\n\ncontent = await download_file(\n    client,\n    'my-bucket',\n    'large-file.zip',\n    chunk_size=1024 * 1024,  # 1MB chunks\n    on_start=on_start,\n    on_update=on_update\n)\n</code></pre>"},{"location":"modules/s3/#delete_file","title":"<code>delete_file</code>","text":"<p>Delete a single file from S3.</p> <pre><code>from tracktolib.s3.s3 import delete_file\n\nresponse = await delete_file(client, 'my-bucket', 'path/to/file.txt')\n</code></pre>"},{"location":"modules/s3/#delete_files","title":"<code>delete_files</code>","text":"<p>Delete multiple files from S3.</p> <pre><code>from tracktolib.s3.s3 import delete_files\n\npaths = ['file1.txt', 'file2.txt', 'folder/file3.txt']\nresponse = await delete_files(\n    client,\n    'my-bucket',\n    paths,\n    quiet=True  # Suppress output\n)\n</code></pre>"},{"location":"modules/s3/#list_files","title":"<code>list_files</code>","text":"<p>List files in a bucket with optional filtering.</p> <pre><code>from tracktolib.s3.s3 import list_files\n\n# List all files in a path\nfiles = await list_files(client, 'my-bucket', 'uploads/')\n\n# With pagination\nfiles = await list_files(\n    client,\n    'my-bucket',\n    'uploads/',\n    max_items=100,\n    page_size=50\n)\n\n# With JMESPath filter (files larger than 100 bytes)\nlarge_files = await list_files(\n    client,\n    'my-bucket',\n    'uploads/',\n    search_query=\"Contents[?Size &gt; `100`][]\"\n)\n</code></pre>"},{"location":"modules/s3/#types","title":"Types","text":""},{"location":"modules/s3/#s3item","title":"<code>S3Item</code>","text":"<p>TypedDict representing an S3 object.</p> <pre><code>from tracktolib.s3.s3 import S3Item\n\n# S3Item structure:\n{\n    'Key': 'uploads/document.pdf',\n    'LastModified': datetime(2024, 1, 15, 10, 30, 0),\n    'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n    'Size': 1024,\n    'StorageClass': 'STANDARD',\n    'Owner': {\n        'DisplayName': 'owner',\n        'ID': 'owner-id'\n    }\n}\n</code></pre>"},{"location":"modules/s3/#jmespath-examples","title":"JMESPath Examples","text":"<p>The <code>search_query</code> parameter uses JMESPath syntax:</p> <pre><code># Files larger than 1MB\n\"Contents[?Size &gt; `1048576`][]\"\n\n# Files modified after a date\n\"Contents[?LastModified &gt; `2024-01-01`][]\"\n\n# Files with specific extension (in Key)\n\"Contents[?ends_with(Key, '.pdf')][]\"\n\n# Combine conditions\n\"Contents[?Size &gt; `100` &amp;&amp; starts_with(Key, 'uploads/')][]\"\n</code></pre>"},{"location":"modules/tests/","title":"Tests","text":"<p>Testing utilities using deepdiff.</p>"},{"location":"modules/tests/#installation","title":"Installation","text":"<pre><code>uv add tracktolib[tests]\n</code></pre>"},{"location":"modules/tests/#dependencies","title":"Dependencies","text":"<ul> <li>deepdiff</li> </ul>"},{"location":"modules/tests/#functions","title":"Functions","text":""},{"location":"modules/tests/#assert_equals","title":"<code>assert_equals</code>","text":"<p>Deep comparison assertion for dictionaries and iterables with detailed diff output.</p> <pre><code>from tracktolib.tests import assert_equals\n\n# Compare dictionaries\nexpected = {'name': 'John', 'age': 30, 'tags': ['admin', 'user']}\nactual = {'name': 'John', 'age': 30, 'tags': ['admin', 'user']}\nassert_equals(expected, actual)\n\n# Compare lists\nexpected = [{'id': 1}, {'id': 2}]\nactual = [{'id': 1}, {'id': 2}]\nassert_equals(expected, actual)\n\n# Ignore list order\nassert_equals(expected, actual, ignore_order=True)\n</code></pre>"},{"location":"modules/tests/#examples","title":"Examples","text":""},{"location":"modules/tests/#basic-usage","title":"Basic Usage","text":"<pre><code>from tracktolib.tests import assert_equals\n\ndef test_user_creation():\n    user = create_user(name='John', email='john@example.com')\n\n    assert_equals(\n        {'name': 'John', 'email': 'john@example.com'},\n        {'name': user.name, 'email': user.email}\n    )\n</code></pre>"},{"location":"modules/tests/#ignoring-order","title":"Ignoring Order","text":"<pre><code>from tracktolib.tests import assert_equals\n\ndef test_tags():\n    expected_tags = ['admin', 'user', 'moderator']\n    actual_tags = ['user', 'admin', 'moderator']\n\n    # This would fail without ignore_order\n    # assert_equals(expected_tags, actual_tags)\n\n    # This passes\n    assert_equals(expected_tags, actual_tags, ignore_order=True)\n</code></pre>"},{"location":"modules/tests/#nested-structures","title":"Nested Structures","text":"<pre><code>from tracktolib.tests import assert_equals\n\ndef test_nested_data():\n    expected = {\n        'user': {\n            'profile': {\n                'name': 'John',\n                'settings': {'theme': 'dark', 'notifications': True}\n            }\n        }\n    }\n\n    actual = get_user_data()\n    assert_equals(expected, actual)\n</code></pre>"},{"location":"modules/tests/#list-of-dictionaries","title":"List of Dictionaries","text":"<pre><code>from tracktolib.tests import assert_equals\n\ndef test_api_response():\n    expected = [\n        {'id': 1, 'name': 'Item 1'},\n        {'id': 2, 'name': 'Item 2'},\n    ]\n\n    response = client.get('/items')\n    assert_equals(expected, response.json())\n</code></pre>"},{"location":"modules/tests/#error-output","title":"Error Output","text":"<p>When assertion fails, <code>assert_equals</code> provides detailed diff information:</p> <pre><code>from tracktolib.tests import assert_equals\n\nexpected = {'name': 'John', 'age': 30}\nactual = {'name': 'Jane', 'age': 25}\n\nassert_equals(expected, actual)\n# AssertionError with output:\n# {'values_changed': {\"root['name']\": {'new_value': 'Jane', 'old_value': 'John'},\n#                     \"root['age']\": {'new_value': 25, 'old_value': 30}}}\n</code></pre>"},{"location":"modules/tests/#integration-with-pytest","title":"Integration with pytest","text":"<pre><code>import pytest\nfrom tracktolib.tests import assert_equals\n\nclass TestUserAPI:\n    def test_get_user(self, client):\n        response = client.get('/users/1')\n\n        assert_equals(\n            {'id': 1, 'name': 'John', 'email': 'john@example.com'},\n            response.json()\n        )\n\n    def test_list_users(self, client):\n        response = client.get('/users')\n\n        assert_equals(\n            [{'id': 1, 'name': 'John'}, {'id': 2, 'name': 'Jane'}],\n            response.json(),\n            ignore_order=True\n        )\n</code></pre>"},{"location":"modules/tests/#why-use-assert_equals","title":"Why Use <code>assert_equals</code>?","text":"<ol> <li>Detailed Diffs: Shows exactly what differs between expected and actual values</li> <li>Deep Comparison: Handles nested structures automatically</li> <li>Order Control: Option to ignore order in lists and sets</li> <li>Pretty Output: Uses <code>pprint</code> for readable error messages</li> </ol>"}]}